# Performance Working Group Meeting Notes â€“ 2025-05-14

### Meta Information

- GitHub Issue: [#8](https://github.com/expressjs/perf-wg/issues/8)


### Discussions at the Meeting

- @wesleytodd were shown a cup with the used Express logo
- Need to define goals 
- To define benchmarking philosophy (micro, integration, end-to-end).
- Way: Track Express performance over new versions rather than other frameworks.
- Focus more on real-world Express usage rather than synthetic Hello World benchmarks.
- @wesleytodd emphasized building benchmarks that can connect sub-package changes to observable performance changes in full Express apps.
- @wesleytodd proposed using flame graphs and CPU metrics (via Linux 'perf', OpenTelemetry, etc.).
- @UlisesGascon NodeSource's NSolid was proposed as a production-grade solution for collecting deep insights without intrusive code.
- @GroophyLifefor proposed his abstractor-based benchmark framework, used in his observability platform Yelix Cloud for macro/micro performance collection.
- We talked about how Express is getting slowed down because of the backward compatibility layers.
- @GroophyLifefor proposed anonymous middleware functions were called out as a major problem for observability, suggested optionally support named middleware functions.

---

### Shared Resources

- @UlisesGascon NSolid (NodeSource): [https://nodesource.com/products/nsolid](https://nodesource.com/products/nsolid)
- @GroophyLifefor's abstractor example: [https://github.com/yelix-cloud/js-hono-deno/blob/main/src/Hono.ts](https://github.com/yelix-cloud/js-hono-deno/blob/main/src/Hono.ts)

---

### Call to Action

- Open issues/PRs in the [perf-wg repo](https://github.com/expressjs/perf-wg).
- Add ideas or edits to [issue #3](https://github.com/expressjs/perf-wg/issues/3).
- Share your work via a GitHub issue, repository or PR.

> If a mistake has been made, please correct it.
> Thank you to everyone who participated ğŸ˜Š
